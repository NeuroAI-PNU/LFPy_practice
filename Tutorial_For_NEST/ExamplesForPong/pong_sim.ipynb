{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to train networks to play pong against each other\n",
    "* https://nest-simulator.readthedocs.io/en/latest/auto_examples/pong/run_simulations.html#id2\n",
    "* The idea for this simulation as well as the core of the R-STDP and Pong implementation are from [1] and were created by Timo Wunderlich and Electronic Vision(s) (The original implementation can be found [here](https://github.com/electronicvisions/model-sw-pong)). The visualization and implementation of dopaminergic learning, as well as changes to the existing codebase were developed by Johannes Gille (2022).\n",
    "\n",
    "### References\n",
    "[1] Wunderlich T., et al (2019). Demonstrating advantages of neuromorphic computation: a pilot study. Frontiers in neuroscience, 13, 260. https://doi.org/10.3389/fnins.2019.00260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:33:57 - setup complete for a pong game between: clean R-STDP and noisy R-STDP.\n",
      "09:33:57 - Starting simulation of 100 iterations of 200ms each.\n",
      "09:33:57 - 0.01: Run 0, score: (0, 0), mean rewards: 0.0, 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oct 26 09:33:57 ConnectionManager [Warning]: \n",
      "    New connections created, connection descriptors previously obtained using \n",
      "    'GetConnections' are now invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:38:40 - Simulation of 100 runs complete after: 0:04:42.528294\n",
      "09:38:40 - saving game data...\n",
      "09:38:40 - saving network data...\n",
      "09:38:40 - Done.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import gzip\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import nest\n",
    "import numpy as np\n",
    "import pong\n",
    "from networks import POLL_TIME, PongNetDopa, PongNetRSTDP\n",
    "\n",
    "\n",
    "class AIPong:\n",
    "    def __init__(self, p1, p2, out_dir=\"\"):\n",
    "        \"\"\"A class to run and store pong simulations of two competing spiking\n",
    "        neural networks.\n",
    "\n",
    "        Args:\n",
    "            p1 (PongNet): Network to play on the left side.\n",
    "            p2 (PongNet): Network to play on the right side.\n",
    "            out_folder (str, optional): Name of the output folder. Defaults to\n",
    "            current time stamp (YYYY-mm-dd-HH-MM-SS).\n",
    "        \"\"\"\n",
    "        self.game = pong.GameOfPong()\n",
    "        self.player1 = p1\n",
    "        self.player2 = p2\n",
    "\n",
    "        if out_dir == \"\":\n",
    "            out_dir = \"{0:%Y-%m-%d-%H-%M-%S}\".format(datetime.datetime.now())\n",
    "        if os.path.exists(out_dir):\n",
    "            print(f\"output folder {out_dir} already exists!\")\n",
    "            sys.exit()\n",
    "        os.mkdir(out_dir)\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "        logging.info(f\"setup complete for a pong game between: {p1} and {p2}.\")\n",
    "\n",
    "    def run_games(self, max_runs=10000):\n",
    "        \"\"\"Runs a simulation of pong games and stores the results.\n",
    "\n",
    "        Args:\n",
    "            max_runs (int, optional): Number of iterations to simulate.\n",
    "            Defaults to 10000.\n",
    "        \"\"\"\n",
    "        self.game_data = []\n",
    "        l_score, r_score = 0, 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.run = 0\n",
    "        biological_time = 0\n",
    "\n",
    "        logging.info(\n",
    "            f\"Starting simulation of {max_runs} iterations of \" f\"{POLL_TIME}ms each.\"\n",
    "        )\n",
    "        while self.run < max_runs:\n",
    "            logging.debug(\"\")\n",
    "            logging.debug(f\"Iteration {self.run}:\")\n",
    "            self.input_index = self.game.ball.get_cell()[1]\n",
    "            self.player1.set_input_spiketrain(self.input_index, biological_time)\n",
    "            self.player2.set_input_spiketrain(self.input_index, biological_time)\n",
    "\n",
    "            if self.run % 100 == 0:\n",
    "                logging.info(\n",
    "                    f\"{round(time.time() - start_time, 2)}: Run \"\n",
    "                    f\"{self.run}, score: {l_score, r_score}, mean rewards: \"\n",
    "                    f\"{round(np.mean(self.player1.mean_reward), 3)}, \"\n",
    "                    f\"{round(np.mean(self.player2.mean_reward), 3)}\"\n",
    "                )\n",
    "\n",
    "            logging.debug(\"Running simulation...\")\n",
    "            nest.Simulate(POLL_TIME)\n",
    "            biological_time = nest.GetKernelStatus(\"biological_time\")\n",
    "\n",
    "            for network, paddle in zip(\n",
    "                [self.player1, self.player2], [self.game.l_paddle, self.game.r_paddle]\n",
    "            ):\n",
    "                network.apply_synaptic_plasticity(biological_time)\n",
    "                network.reset()\n",
    "\n",
    "                position_diff = network.winning_neuron - paddle.get_cell()[1]\n",
    "                if position_diff > 0:\n",
    "                    paddle.move_up()\n",
    "                elif position_diff == 0:\n",
    "                    paddle.dont_move()\n",
    "                else:\n",
    "                    paddle.move_down()\n",
    "\n",
    "            self.game.step()\n",
    "            self.run += 1\n",
    "            self.game_data.append(\n",
    "                [\n",
    "                    self.game.ball.get_pos(),\n",
    "                    self.game.l_paddle.get_pos(),\n",
    "                    self.game.r_paddle.get_pos(),\n",
    "                    (l_score, r_score),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if self.game.result == pong.RIGHT_SCORE:\n",
    "                self.game.reset_ball(False)\n",
    "                r_score += 1\n",
    "            elif self.game.result == pong.LEFT_SCORE:\n",
    "                self.game.reset_ball(True)\n",
    "                l_score += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.info(\n",
    "            f\"Simulation of {max_runs} runs complete after: \"\n",
    "            f\"{datetime.timedelta(seconds=end_time - start_time)}\"\n",
    "        )\n",
    "\n",
    "        self.game_data = np.array(self.game_data)\n",
    "\n",
    "        out_data = dict()\n",
    "        out_data[\"ball_pos\"] = self.game_data[:, 0]\n",
    "        out_data[\"left_paddle\"] = self.game_data[:, 1]\n",
    "        out_data[\"right_paddle\"] = self.game_data[:, 2]\n",
    "        out_data[\"score\"] = self.game_data[:, 3]\n",
    "\n",
    "        logging.info(\"saving game data...\")\n",
    "        with open(os.path.join(self.out_dir, \"gamestate.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(out_data, file)\n",
    "\n",
    "        logging.info(\"saving network data...\")\n",
    "\n",
    "        for net, filename in zip(\n",
    "            [self.player1, self.player2], [\"data_left.pkl.gz\", \"data_right.pkl.gz\"]\n",
    "        ):\n",
    "            with gzip.open(os.path.join(self.out_dir, filename), \"w\") as file:\n",
    "                output = {\"network_type\": repr(net), \"with_noise\": net.apply_noise}\n",
    "                performance_data = net.get_performance_data()\n",
    "                output[\"rewards\"] = performance_data[0]\n",
    "                output[\"weights\"] = performance_data[1]\n",
    "                pickle.dump(output, file)\n",
    "\n",
    "        logging.info(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest.set_verbosity(\"M_WARNING\")\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--runs\", type=int, default=100, help=\"Number of game steps to simulate.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--debug\", action=\"store_true\", help=\"Verbose debugging output.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out_dir\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"Directory to save experiments to. Defaults to \\\n",
    "                        current time stamp (YYYY-mm-dd-HH-MM-SS)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--players\",\n",
    "        nargs=2,\n",
    "        type=str,\n",
    "        choices=[\"r\", \"rn\", \"d\", \"dn\"],\n",
    "        default=[\"r\", \"rn\"],\n",
    "        help=\"\"\"Types of networks that compete against each other. four learning\n",
    "        rule configuations are available: r:  r-STDP without noise, rn: r-STDP\n",
    "        with noisy input, d:  dopaminergic synapses without noise,\n",
    "        dn: dopaminergic synapses with noisy input.\"\"\",\n",
    "    )\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    level = logging.DEBUG if args.debug else logging.INFO\n",
    "    format = \"%(asctime)s - %(message)s\"\n",
    "    datefmt = \"%H:%M:%S\"\n",
    "    logging.basicConfig(level=level, format=format, datefmt=datefmt)\n",
    "\n",
    "    p1, p2 = args.players\n",
    "    if p1[0] == p2[0] == \"d\":\n",
    "        logging.error(\n",
    "            \"\"\"Nest currently (August 2022) does not support\n",
    "        addressing multiple populations of dopaminergic synapses because all of\n",
    "        them recieve their signal from a single volume transmitter. For this\n",
    "        reason, no two dopaminergic networks can be trained simultaneously. One\n",
    "        of the players needs to be changed to the R-STDP type.\"\"\"\n",
    "        )\n",
    "        sys.exit()\n",
    "\n",
    "    apply_noise = len(p1) > 1\n",
    "    if p1[0] == \"r\":\n",
    "        p1 = PongNetRSTDP(apply_noise)\n",
    "    else:\n",
    "        p1 = PongNetDopa(apply_noise)\n",
    "\n",
    "    apply_noise = len(p2) > 1\n",
    "    if p2[0] == \"r\":\n",
    "        p2 = PongNetRSTDP(apply_noise)\n",
    "    else:\n",
    "        p2 = PongNetDopa(apply_noise)\n",
    "\n",
    "    AIPong(p1, p2, args.out_dir).run_games(max_runs=args.runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
